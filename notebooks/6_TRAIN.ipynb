{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from dsvit.dataset import BrainTumorDataset\n",
    "from dsvit.model import DSViTDetector, ViTBaseline, DSViT_NoPreEncoder, DSViT_NoMultiScale\n",
    "import h5py\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BrainTumorDataset(root_dir=\"/Users/darshdave/Documents/BRAINTUMOR/DATASET/FILES/\")\n",
    "\n",
    "with h5py.File('/Users/darshdave/Documents/BRAINTUMOR/DATASET/cvind.mat', 'r') as f:\n",
    "    split_labels = np.array(f['cvind']).squeeze().astype(int)\n",
    "\n",
    "train_ids = np.where(split_labels == 1)[0]\n",
    "val_ids   = np.where(split_labels == 2)[0]\n",
    "\n",
    "train_loader = DataLoader(Subset(dataset, train_ids), batch_size=8, shuffle=True)\n",
    "val_loader   = DataLoader(Subset(dataset, val_ids), batch_size=8)\n",
    "\n",
    "# subset_ids = list(range(6))\n",
    "# train_loader = DataLoader(Subset(dataset, subset_ids), batch_size=1, shuffle=True)\n",
    "# val_loader   = DataLoader(Subset(dataset, subset_ids), batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DSViTDetector()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            _, logits = model(x)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend((y - 1).cpu().numpy()) \n",
    "    return accuracy_score(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 200.7608, Val Acc: 0.5000\n",
      "✅ Model saved.\n",
      "Epoch 2/10, Train Loss: 196.5875, Val Acc: 0.5000\n",
      "Epoch 3/10, Train Loss: 194.5485, Val Acc: 0.5000\n",
      "Epoch 4/10, Train Loss: 191.9150, Val Acc: 0.5000\n",
      "Epoch 5/10, Train Loss: 189.4788, Val Acc: 0.5000\n",
      "Epoch 6/10, Train Loss: 187.0057, Val Acc: 0.6667\n",
      "✅ Model saved.\n",
      "Epoch 7/10, Train Loss: 184.0167, Val Acc: 0.5000\n",
      "Epoch 8/10, Train Loss: 180.9163, Val Acc: 1.0000\n",
      "✅ Model saved.\n",
      "Epoch 9/10, Train Loss: 177.6254, Val Acc: 1.0000\n",
      "Epoch 10/10, Train Loss: 174.3467, Val Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        bbox_pred, class_logits = model(x)\n",
    "        bbox_gt = torch.tensor([[30.0, 30.0, 40.0, 40.0]] * x.size(0)).to(device)  # Dummy for now\n",
    "\n",
    "        loss = criterion_cls(class_logits, y - 1) + criterion_bbox(bbox_pred, bbox_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"/Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/best_dsvit_detector.pth\")\n",
    "        print(\"✅ Model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABILATION TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 209.3240, Val Acc: 0.5000\n",
      "✅ ViT-Baseline model saved.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = ViTBaseline().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:  # use 6-sample mock loader if needed\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        bbox_pred, class_logits = model(x)\n",
    "        bbox_gt = torch.tensor([[30.0, 30.0, 40.0, 40.0]] * x.size(0)).to(device)\n",
    "\n",
    "        # ✅ shift labels from [1,2,3] → [0,1,2]\n",
    "        loss = criterion_cls(class_logits, y - 1) + criterion_bbox(bbox_pred, bbox_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_acc = evaluate(model, val_loader)  # You already have this function\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {running_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"/Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/ViT-Baseline.pth\")\n",
    "        print(\"✅ ViT-Baseline model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 207.0999, Val Acc: 0.5000\n",
      "✅ Saved: /Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Pre-Encoder.pth\n",
      "Epoch 2/10, Loss: 200.7487, Val Acc: 0.5000\n",
      "Epoch 3/10, Loss: 195.8178, Val Acc: 0.5000\n",
      "Epoch 4/10, Loss: 194.3833, Val Acc: 0.5000\n",
      "Epoch 5/10, Loss: 191.4619, Val Acc: 0.5000\n",
      "Epoch 6/10, Loss: 188.5253, Val Acc: 0.6667\n",
      "✅ Saved: /Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Pre-Encoder.pth\n",
      "Epoch 7/10, Loss: 185.8213, Val Acc: 0.5000\n",
      "Epoch 8/10, Loss: 182.8652, Val Acc: 1.0000\n",
      "✅ Saved: /Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Pre-Encoder.pth\n",
      "Epoch 9/10, Loss: 179.9650, Val Acc: 0.8333\n",
      "Epoch 10/10, Loss: 176.7107, Val Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = DSViT_NoPreEncoder().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        bbox_pred, class_logits = model(x)\n",
    "        bbox_gt = torch.tensor([[30.0, 30.0, 40.0, 40.0]] * x.size(0)).to(device)\n",
    "\n",
    "        loss = criterion_cls(class_logits, y - 1) + criterion_bbox(bbox_pred, bbox_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        path = \"/Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Pre-Encoder.pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"✅ Saved: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 211.9580, Val Acc: 0.5000\n",
      "✅ Saved: /Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Multi-Scale.pth\n",
      "Epoch 2/10, Loss: 199.9567, Val Acc: 0.5000\n",
      "Epoch 3/10, Loss: 197.0060, Val Acc: 0.5000\n",
      "Epoch 4/10, Loss: 194.8164, Val Acc: 0.6667\n",
      "✅ Saved: /Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Multi-Scale.pth\n",
      "Epoch 5/10, Loss: 192.1568, Val Acc: 0.5000\n",
      "Epoch 6/10, Loss: 189.6660, Val Acc: 0.5000\n",
      "Epoch 7/10, Loss: 187.0334, Val Acc: 0.5000\n",
      "Epoch 8/10, Loss: 184.5239, Val Acc: 0.5000\n",
      "Epoch 9/10, Loss: 181.6388, Val Acc: 0.6667\n",
      "Epoch 10/10, Loss: 178.6108, Val Acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = DSViT_NoMultiScale().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.SmoothL1Loss()\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_acc = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        bbox_pred, class_logits = model(x)\n",
    "        bbox_gt = torch.tensor([[30.0, 30.0, 40.0, 40.0]] * x.size(0)).to(device)\n",
    "\n",
    "        loss = criterion_cls(class_logits, y - 1) + criterion_bbox(bbox_pred, bbox_gt)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        path = \"/Users/darshdave/Documents/BRAINTUMOR/DSVIT/model-weight/No_Multi-Scale.pth\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"✅ Saved: {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
